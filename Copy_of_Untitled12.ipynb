{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1c1If3-SibD",
        "outputId": "6eddeba5-9fb2-4613-f04a-ee600c605476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/facebookresearch/detectron2.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMON LIBRARIES\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# DATA SET PREPARATION AND LOADING\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# VISUALIZATION\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# CONFIGURATION\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# EVALUATION\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# TRAINING\n",
        "from detectron2.engine import DefaultTrainer"
      ],
      "metadata": {
        "id": "s6FBrmkZX8jc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow -q\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"p7ll5rTRQYfRRG5zTZYK\")\n",
        "project = rf.workspace(\"amodic2c\").project(\"paddy_weed\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"coco-segmentation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIXD2y1vTMVX",
        "outputId": "f8b76cc8-6e87-4a6a-d20d-94563f403760"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/83.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in paddy_weed-2 to coco-segmentation:: 100%|██████████| 2406142/2406142 [00:40<00:00, 59229.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to paddy_weed-2 in coco-segmentation:: 100%|██████████| 27951/27951 [00:11<00:00, 2417.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = dataset.location"
      ],
      "metadata": {
        "id": "eTDvu50cXrIN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "annotation_file = \"/content/paddy_weed-2/train/_annotations.coco.json\"\n",
        "\n",
        "with open(annotation_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "category_ids = {c[\"id\"]: c[\"name\"] for c in data[\"categories\"]}\n",
        "print(\"Category Mapping:\", category_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFKnwWsPTiSV",
        "outputId": "19dc6888-18ce-4f41-e726-d47b5425d162"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category Mapping: {0: 'weed', 1: 'Paddy', 2: 'Weed'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def count_instances(annotation_file):\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    category_counts = {}\n",
        "\n",
        "    for ann in coco_data[\"annotations\"]:\n",
        "        cat_id = ann[\"category_id\"]\n",
        "        category_counts[cat_id] = category_counts.get(cat_id, 0) + 1\n",
        "\n",
        "    # Print instance counts per category\n",
        "    print(\"Instance counts per category:\")\n",
        "    for cat_id, count in category_counts.items():\n",
        "        category_name = next((c[\"name\"] for c in coco_data[\"categories\"] if c[\"id\"] == cat_id), f\"Unknown ({cat_id})\")\n",
        "        print(f\"{category_name} (ID {cat_id}): {count} instances\")\n",
        "\n",
        "    print(f\"\\nTotal annotations: {len(coco_data['annotations'])}\")\n",
        "\n",
        "# Usage\n",
        "count_instances(\"/content/paddy_weed-2/train/_annotations.coco.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VkPziLWVDs9",
        "outputId": "29dedada-6c94-4125-d35c-7114a9a05f73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instance counts per category:\n",
            "Paddy (ID 1): 20508 instances\n",
            "Weed (ID 2): 31356 instances\n",
            "\n",
            "Total annotations: 51864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def fix_annotations(input_file, output_file):\n",
        "    with open(input_file, \"r\") as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    # Remove Paddy (ID 1)\n",
        "    filtered_annotations = [ann for ann in coco_data[\"annotations\"] if ann[\"category_id\"] != 1]\n",
        "\n",
        "    # Merge Weed categories (0 & 2) into a single ID 1\n",
        "    for ann in filtered_annotations:\n",
        "        if ann[\"category_id\"] in [0, 2]:\n",
        "            ann[\"category_id\"] = 1  # Assign new ID for weed\n",
        "\n",
        "    # Update categories to keep only one \"Weed\"\n",
        "    coco_data[\"categories\"] = [{\"id\": 1, \"name\": \"weed\"}]\n",
        "\n",
        "    # Update dataset\n",
        "    coco_data[\"annotations\"] = filtered_annotations\n",
        "\n",
        "    # Save new annotation file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(coco_data, f, indent=4)\n",
        "\n",
        "    print(f\"✅ New annotation file saved as: {output_file}\")\n",
        "    print(f\"🔹 Remaining Weed Instances: {len(filtered_annotations)}\")\n",
        "\n",
        "# Usage\n",
        "fix_annotations(\"/content/paddy_weed-2/valid/_annotations.coco.json\",\n",
        "                \"/content/paddy_weed-2/valid/_annotations_fixed.coco.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQQLizwmWmG1",
        "outputId": "4e88ddd4-114d-48bf-c36a-3d4170401a74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New annotation file saved as: /content/paddy_weed-2/valid/_annotations_fixed.coco.json\n",
            "🔹 Remaining Weed Instances: 1259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SET_NAME = dataset_path.split(\"/\")[-1].replace(\" \", \"-\")\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations_fixed.coco.json\""
      ],
      "metadata": {
        "id": "lEQEwPjrW6qO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN SET\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# TEST SET\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TEST_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# VALID SET\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=VALID_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=VALID_DATA_SET_ANN_FILE_PATH,\n",
        "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ],
      "metadata": {
        "id": "nXxTCwuoX4ms"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DATA_SET_ANN_FILE_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "06cpYLQVphmK",
        "outputId": "e756b190-55ee-412c-e3f3-388008c653d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/paddy_weed-2/test/_annotations_fixed.coco.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifqkyAueYE8l",
        "outputId": "182b9a1a-6649-4cb5-dd4d-4afcbaf2b849"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paddy_weed-2-train', 'paddy_weed-2-test', 'paddy_weed-2-valid']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import HookBase, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.solver import build_lr_scheduler\n",
        "from detectron2 import model_zoo\n",
        "import torch\n",
        "import json\n",
        "\n",
        "class LRSchedulerWithEarlyStopping(HookBase):\n",
        "    def __init__(self, patience=5):\n",
        "        self.patience = patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.waiting = 0\n",
        "\n",
        "    def after_step(self):\n",
        "        stats = self.trainer.storage.latest()\n",
        "        current_loss = stats.get(\"total_loss\", float(\"inf\"))\n",
        "\n",
        "        if isinstance(current_loss, (list, tuple)):\n",
        "            current_loss = current_loss[0]\n",
        "\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.waiting = 0\n",
        "        else:\n",
        "            self.waiting += 1\n",
        "\n",
        "        if self.waiting >= self.patience and self.trainer.scheduler is not None:\n",
        "            self.trainer.scheduler.step()\n",
        "            self.waiting = 0\n",
        "\n",
        "class WeedTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__(cfg)\n",
        "        self.scheduler = build_lr_scheduler(cfg, self.optimizer)\n",
        "\n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.append(LRSchedulerWithEarlyStopping(patience=5))\n",
        "        return hooks\n",
        "\n",
        "\n",
        "def get_optimized_weed_detection_config():\n",
        "    cfg = get_cfg()\n",
        "    ARCHITECTURE = \"mask_rcnn_X_101_32x8d_FPN_3x\"\n",
        "    CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "\n",
        "    cfg.OUTPUT_DIR = \"/content/output\"\n",
        "\n",
        "    # Dataset Configuration\n",
        "    cfg.DATASETS.TRAIN = (\"paddy_weed-2-train\",)\n",
        "    cfg.DATASETS.TEST = (\"paddy_weed-2-test\",)\n",
        "\n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "    cfg.MODEL.MASK_ON = True\n",
        "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Optimized Training Hyperparameters\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "    cfg.SOLVER.BASE_LR = 0.0003\n",
        "    cfg.SOLVER.MAX_ITER = 15000\n",
        "    cfg.SOLVER.STEPS = (20000, 25000, 28000)\n",
        "    cfg.SOLVER.GAMMA = 0.1\n",
        "    cfg.SOLVER.WARMUP_ITERS = 2000\n",
        "    cfg.SOLVER.WEIGHT_DECAY = 0.00025\n",
        "    cfg.SOLVER.MOMENTUM = 0.9\n",
        "    cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
        "    cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
        "\n",
        "    # ROI Head Configuration\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
        "    cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.25\n",
        "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
        "    cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.3, 0.5, 0.7]\n",
        "    cfg.MODEL.ROI_HEADS.IOU_LABELS = [0, 1, 1, 1]\n",
        "\n",
        "    # RPN Configuration\n",
        "    cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256\n",
        "    cfg.MODEL.RPN.POSITIVE_FRACTION = 0.5\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 6000\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 1000\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 3000\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 500\n",
        "    cfg.MODEL.RPN.NMS_THRESH = 0.7\n",
        "\n",
        "    # Anchor Generator\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256]]\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0]]\n",
        "\n",
        "    # Input Configuration\n",
        "    cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)\n",
        "    cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
        "    cfg.INPUT.MIN_SIZE_TEST = 800\n",
        "    cfg.INPUT.MAX_SIZE_TEST = 1333\n",
        "    cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
        "\n",
        "    # Data Augmentation\n",
        "    cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
        "    cfg.INPUT.BRIGHTNESS = 1.0\n",
        "    cfg.INPUT.CONTRAST = 1.0\n",
        "    cfg.INPUT.SATURATION = 1.0\n",
        "    cfg.INPUT.ROTATION = [-15, 15]\n",
        "\n",
        "    # Dataloader\n",
        "    cfg.DATALOADER.NUM_WORKERS = 4\n",
        "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
        "    cfg.DATALOADER.ASPECT_RATIO_GROUPING = True\n",
        "\n",
        "    # Evaluation\n",
        "    cfg.TEST.EVAL_PERIOD = 1000\n",
        "    cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
        "    cfg.TEST.PRECISE_BN.ENABLED = True\n",
        "    cfg.TEST.PRECISE_BN.NUM_ITER = 200\n",
        "\n",
        "    # Test-Time Augmentation\n",
        "    cfg.TEST.AUG.ENABLED = True\n",
        "    cfg.TEST.AUG.MIN_SIZES = (600, 700, 800, 900, 1000)\n",
        "    cfg.TEST.AUG.MAX_SIZE = 1400\n",
        "    cfg.TEST.AUG.FLIP = True\n",
        "\n",
        "    # Mixed Precision Training\n",
        "    cfg.SOLVER.AMP.ENABLED = False\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "cfg = get_optimized_weed_detection_config()\n",
        "trainer = WeedTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)  # Resume from last checkpoint\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "NIOR3LpeYJKU",
        "outputId": "63464459-c7ba-44c6-e77f-86ba5bbf7953"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 18.12 MiB is free. Process 16220 has 14.72 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 7.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6c2079bfabdd>\u001b[0m in \u001b[0;36m<cell line: 130>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimized_weed_detection_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeedTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Resume from last checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-6c2079bfabdd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWeedTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Assume these objects must be constructed in this order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \"\"\"\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/modeling/meta_arch/build.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmeta_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETA_ARCHITECTURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETA_ARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_log_api_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modeling.meta_arch.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 18.12 MiB is free. Process 16220 has 14.72 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 7.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('config.yaml', 'w')\n",
        "f.write(cfg.dump())\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Y85joATwp9jB"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}